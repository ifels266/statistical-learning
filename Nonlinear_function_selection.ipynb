{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0aa441b",
   "metadata": {},
   "source": [
    "# Bachelor End Project (BEP) - Els Brouwer - May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7fc5a",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0ae699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm  # progress bar\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8c2cc",
   "metadata": {},
   "source": [
    "Check sklearn version for default values used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1696d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f1593",
   "metadata": {},
   "source": [
    "# 2. Non-Linear Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac2a90",
   "metadata": {},
   "source": [
    "## 2.1 Generating Non Linear High Dimensional Data Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e317f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nonlinear_data(n_observations, n_informative, informative_ratio, noise_amplitude, random_seed, function_number):\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Compute total number of features\n",
    "    n_features = int(n_informative / informative_ratio)\n",
    "\n",
    "    # Generate random feature matrix\n",
    "    X = np.random.randn(n_observations, n_features)\n",
    "\n",
    "    # Extract only the first 5 informative features for signal generation\n",
    "    X1, X2, X3, X4, X5 = X[:, 0], X[:, 1], X[:, 2], X[:, 3], X[:, 4]\n",
    "\n",
    "    # Compute nonlinear signal based on function number\n",
    "    if function_number == 1:\n",
    "        # Additive sine and square\n",
    "        nonlinear_part = np.sin(X1) + X2**2 + np.sin(X3) + X4**2 + np.sin(X5)\n",
    "\n",
    "    elif function_number == 2:\n",
    "        # Pairwise interactions with arctan\n",
    "        nonlinear_part = np.arctan(X1 * X2) + np.arctan(X3 * X4) + np.arctan(X5)\n",
    "\n",
    "    elif function_number == 3:\n",
    "        # Compositional nonlinearity with log and sin\n",
    "        nonlinear_part = np.log(np.abs(np.sin(X1) * X2) + 1) + \\\n",
    "                         np.log(np.abs(np.sin(X3) * X4) + 1) + X5\n",
    "\n",
    "    elif function_number == 4:\n",
    "        # Thresholded quadratics (sparse)\n",
    "        nonlinear_part = np.where(X1 > 1, X1**2, 0) + \\\n",
    "                         np.where(X2 > 1, X2**2, 0) + \\\n",
    "                         np.where(X3 > 1, X3**2, 0) + \\\n",
    "                         np.where(X4 > 1, X4**2, 0) + \\\n",
    "                         np.where(X5 > 1, X5**2, 0)\n",
    "\n",
    "    elif function_number == 5:\n",
    "        # Mixed univariate nonlinearities\n",
    "        nonlinear_part = np.sin(X1) + np.log(np.abs(X2) + 1) + X3**2 + \\\n",
    "                         np.arctan(X4) + np.exp(X5)\n",
    "\n",
    "    elif function_number == 6:\n",
    "        # Interaction + composition\n",
    "        nonlinear_part = (X1 * X2) + np.sqrt(np.abs(X3)) + \\\n",
    "                         np.log2(np.abs(X4) + 1) + np.sin(X5)\n",
    "\n",
    "    elif function_number == 7:\n",
    "        # Deep composition\n",
    "        nonlinear_part = np.sin(np.log(np.abs(X1 * X2) + 1)) + \\\n",
    "                         (X3 * X4) + np.exp(np.sqrt(np.abs(X5)))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"function_number must be an integer between 1 and 7\")\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    y = nonlinear_part + noise_amplitude * np.random.randn(n_observations)\n",
    "\n",
    "    return X, y, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052bee2",
   "metadata": {},
   "source": [
    "## 2.2 Penalized Regression with Ridge (Non-Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6a987",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.11.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # === Parameters ===\n",
    "# n_observations_train = 100  # Fixed number of observations for training\n",
    "# n_observations_test = 100  # Test set of 100 observations\n",
    "# n_observations = n_observations_test + n_observations_train  # Total observations\n",
    "# n_informative = 5  # Number of truly informative features\n",
    "# n_simulations = 50\n",
    "# n_folds = 5\n",
    "# alpha_grid = {'ridge__alpha': np.logspace(-4, 4, 30)}\n",
    "# informative_ratios = [0.01]\n",
    "# noise_amplitudes = [0.01]\n",
    "# function_numbers = range(1, 8)  # Nonlinear functions 1 through 7\n",
    "\n",
    "# # Store combined mean results\n",
    "# ridge_nonlinear_functions_results = []\n",
    "\n",
    "# # === Loop over functions ===\n",
    "# for func_num in function_numbers:\n",
    "#     print(f\"\\n=== Running simulations for nonlinear function #{func_num} ===\")\n",
    "\n",
    "#     for noise_amplitude in noise_amplitudes:\n",
    "#         print(f\"Noise amplitude: {noise_amplitude}\")\n",
    "\n",
    "#         for informative_ratio in informative_ratios:\n",
    "#             print(f\"Informative ratio: {informative_ratio}\")\n",
    "\n",
    "#             # Initialize result lists for this setting\n",
    "#             mse_list = []\n",
    "#             precision5_list = []\n",
    "#             precision10_list = []\n",
    "\n",
    "#             # === Simulations ===\n",
    "#             for sim in tqdm(range(n_simulations), desc=f\"Func {func_num} - Simulations\"):\n",
    "#                 seed = 42 + sim\n",
    "\n",
    "#                 # === Data generation ===\n",
    "#                 X, y, n_features = generate_nonlinear_data(\n",
    "#                     n_observations,\n",
    "#                     n_informative,\n",
    "#                     informative_ratio,\n",
    "#                     noise_amplitude,\n",
    "#                     seed,\n",
    "#                     func_num\n",
    "#                 )\n",
    "\n",
    "#                 # Split into train and test\n",
    "#                 X_train, y_train = X[:n_observations_train], y[:n_observations_train]\n",
    "#                 X_test, y_test = X[n_observations_train:], y[n_observations_train:]\n",
    "\n",
    "#                 # === Ridge pipeline ===\n",
    "#                 ridge_pipeline = Pipeline([\n",
    "#                     ('scaler', StandardScaler()),\n",
    "#                     ('ridge', Ridge(random_state=42))\n",
    "#                 ])\n",
    "\n",
    "#                 grid_search = GridSearchCV(\n",
    "#                     ridge_pipeline,\n",
    "#                     param_grid=alpha_grid,\n",
    "#                     cv=n_folds,\n",
    "#                     scoring='neg_mean_squared_error',\n",
    "#                     n_jobs=-1\n",
    "#                 )\n",
    "\n",
    "#                 # === Fit model ===\n",
    "#                 grid_search.fit(X_train, y_train)\n",
    "#                 best_model = grid_search.best_estimator_\n",
    "\n",
    "#                 # === Evaluate on test set ===\n",
    "#                 y_pred = best_model.predict(X_test)\n",
    "#                 mse = mean_squared_error(y_test, y_pred)\n",
    "#                 mse_list.append(mse)\n",
    "\n",
    "#                 # === Precision@k ===\n",
    "#                 coef = best_model.named_steps['ridge'].coef_\n",
    "#                 coef_magnitudes = np.abs(coef)\n",
    "\n",
    "#                 top_5_indices = np.argsort(coef_magnitudes)[-5:][::-1]\n",
    "#                 top_10_indices = np.argsort(coef_magnitudes)[-10:][::-1]\n",
    "\n",
    "#                 correct_top_5 = np.sum(top_5_indices < n_informative)\n",
    "#                 correct_top_10 = np.sum(top_10_indices < n_informative)\n",
    "\n",
    "#                 precision5 = correct_top_5 / 5\n",
    "#                 precision10 = correct_top_10 / 5\n",
    "\n",
    "#                 precision5_list.append(precision5)\n",
    "#                 precision10_list.append(precision10)\n",
    "\n",
    "#             # === Aggregate results ===\n",
    "#             mean_mse = np.mean(mse_list)\n",
    "#             std_mse = np.std(mse_list)\n",
    "#             mean_precision5 = np.mean(precision5_list)\n",
    "#             std_precision5 = np.std(precision5_list)\n",
    "#             mean_precision10 = np.mean(precision10_list)\n",
    "#             std_precision10 = np.std(precision10_list)\n",
    "\n",
    "#             ridge_nonlinear_functions_results.append({\n",
    "#                 'function_number': func_num,\n",
    "#                 'noise': noise_amplitude,\n",
    "#                 'informative_ratio': informative_ratio,\n",
    "#                 'n_features': n_features,\n",
    "#                 'mean_mse': mean_mse,\n",
    "#                 'std_mse': std_mse,\n",
    "#                 'mean_precision5': mean_precision5,\n",
    "#                 'std_precision5': std_precision5,\n",
    "#                 'mean_precision10': mean_precision10,\n",
    "#                 'std_precision10': std_precision10\n",
    "#             })\n",
    "\n",
    "# # === Save results ===\n",
    "# df_ridge_results = pd.DataFrame(ridge_nonlinear_functions_results)\n",
    "# df_ridge_results.to_csv('Ridge_nonlinear_functions_mean_MSE.csv', index=False)\n",
    "# print(\"Saved Ridge nonlinear functions mean MSE results to 'Ridge_nonlinear_functions_mean_MSE.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13e027",
   "metadata": {},
   "source": [
    "## 2.3 Penalized Regression with Lasso (Non-Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7a24d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.11.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # === Parameters ===\n",
    "# n_observations_train = 100  # Fixed number of observations for training\n",
    "# n_observations_test = 100  # Test set of 100 observations\n",
    "# n_observations = n_observations_test + n_observations_train  # Total observations\n",
    "# n_informative = 5  # Number of truly informative features\n",
    "# n_simulations = 50\n",
    "# n_folds = 5\n",
    "# alpha_grid = {'lasso__alpha': np.logspace(-4, 4, 30)}\n",
    "# informative_ratios = [0.01]\n",
    "# noise_amplitudes = [0.01]\n",
    "# function_numbers = range(1, 8)  # Nonlinear functions 1 through 7\n",
    "\n",
    "# # Store combined mean results\n",
    "# lasso_nonlinear_functions_results = []\n",
    "\n",
    "# # === Loop over functions ===\n",
    "# for func_num in function_numbers:\n",
    "#     print(f\"\\n=== Running simulations for nonlinear function #{func_num} ===\")\n",
    "\n",
    "#     for noise_amplitude in noise_amplitudes:\n",
    "#         print(f\"Noise amplitude: {noise_amplitude}\")\n",
    "\n",
    "#         for informative_ratio in informative_ratios:\n",
    "#             print(f\"Informative ratio: {informative_ratio}\")\n",
    "\n",
    "#             # Initialize result lists for this setting\n",
    "#             mse_list = []\n",
    "#             precision5_list = []\n",
    "#             precision10_list = []\n",
    "\n",
    "#             # === Simulations ===\n",
    "#             for sim in tqdm(range(n_simulations), desc=f\"Func {func_num} - Simulations\"):\n",
    "#                 seed = 42 + sim\n",
    "\n",
    "#                 # === Data generation ===\n",
    "#                 X, y, n_features = generate_nonlinear_data(\n",
    "#                     n_observations,\n",
    "#                     n_informative,\n",
    "#                     informative_ratio,\n",
    "#                     noise_amplitude,\n",
    "#                     seed,\n",
    "#                     func_num\n",
    "#                 )\n",
    "\n",
    "#                 # Split into train and test\n",
    "#                 X_train, y_train = X[:n_observations_train], y[:n_observations_train]\n",
    "#                 X_test, y_test = X[n_observations_train:], y[n_observations_train:]\n",
    "\n",
    "#                 # === Lasso pipeline ===\n",
    "#                 lasso_pipeline = Pipeline([\n",
    "#                     ('scaler', StandardScaler()),\n",
    "#                     ('lasso', Lasso(max_iter=10000, random_state=42))\n",
    "#                 ])\n",
    "\n",
    "#                 grid_search = GridSearchCV(\n",
    "#                     lasso_pipeline,\n",
    "#                     param_grid=alpha_grid,\n",
    "#                     cv=n_folds,\n",
    "#                     scoring='neg_mean_squared_error',\n",
    "#                     n_jobs=-1\n",
    "#                 )\n",
    "\n",
    "#                 # === Fit model ===\n",
    "#                 grid_search.fit(X_train, y_train)\n",
    "#                 best_model = grid_search.best_estimator_\n",
    "\n",
    "#                 # === Evaluate on test set ===\n",
    "#                 y_pred = best_model.predict(X_test)\n",
    "#                 mse = mean_squared_error(y_test, y_pred)\n",
    "#                 mse_list.append(mse)\n",
    "\n",
    "#                 # === Precision@k ===\n",
    "#                 coef = best_model.named_steps['lasso'].coef_\n",
    "#                 coef_magnitudes = np.abs(coef)\n",
    "\n",
    "#                 top_5_indices = np.argsort(coef_magnitudes)[-5:][::-1]\n",
    "#                 top_10_indices = np.argsort(coef_magnitudes)[-10:][::-1]\n",
    "\n",
    "#                 correct_top_5 = np.sum(top_5_indices < n_informative)\n",
    "#                 correct_top_10 = np.sum(top_10_indices < n_informative)\n",
    "\n",
    "#                 precision5 = correct_top_5 / 5\n",
    "#                 precision10 = correct_top_10 / 5\n",
    "\n",
    "#                 precision5_list.append(precision5)\n",
    "#                 precision10_list.append(precision10)\n",
    "\n",
    "#             # === Aggregate results ===\n",
    "#             mean_mse = np.mean(mse_list)\n",
    "#             std_mse = np.std(mse_list)\n",
    "#             mean_precision5 = np.mean(precision5_list)\n",
    "#             std_precision5 = np.std(precision5_list)\n",
    "#             mean_precision10 = np.mean(precision10_list)\n",
    "#             std_precision10 = np.std(precision10_list)\n",
    "\n",
    "#             lasso_nonlinear_functions_results.append({\n",
    "#                 'function_number': func_num,\n",
    "#                 'noise': noise_amplitude,\n",
    "#                 'informative_ratio': informative_ratio,\n",
    "#                 'n_features': n_features,\n",
    "#                 'mean_mse': mean_mse,\n",
    "#                 'std_mse': std_mse,\n",
    "#                 'mean_precision5': mean_precision5,\n",
    "#                 'std_precision5': std_precision5,\n",
    "#                 'mean_precision10': mean_precision10,\n",
    "#                 'std_precision10': std_precision10\n",
    "#             })\n",
    "\n",
    "# # === Save results ===\n",
    "# df_lasso_results = pd.DataFrame(lasso_nonlinear_functions_results)\n",
    "# df_lasso_results.to_csv('Lasso_nonlinear_functions_mean_MSE.csv', index=False)\n",
    "# print(\"Saved Lasso nonlinear functions mean MSE results to 'Lasso_nonlinear_functions_mean_MSE.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd335f",
   "metadata": {},
   "source": [
    "## 2.4 Random Forest (Non-Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c486e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.11.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # === Parameters ===\n",
    "# n_observations_train = 100  # Fixed number of observations for training\n",
    "# n_observations_test = 100   # Test set of 100 observations\n",
    "# n_observations = n_observations_train + n_observations_test  # Total observations\n",
    "# n_informative = 5           # Number of truly informative features\n",
    "# n_simulations = 50\n",
    "# n_folds = 5\n",
    "# informative_ratios = [0.01]\n",
    "# noise_amplitudes = [0.01]\n",
    "# function_numbers = range(1, 8)  # Nonlinear functions 1 through 7\n",
    "\n",
    "# # Store combined mean results\n",
    "# rf_nonlinear_functions_results = []\n",
    "\n",
    "# for func_num in function_numbers:\n",
    "#     print(f\"\\n=== Running simulations for nonlinear function #{func_num} ===\")\n",
    "\n",
    "#     for noise_amplitude in noise_amplitudes:\n",
    "#         print(f\"Noise amplitude: {noise_amplitude}\")\n",
    "\n",
    "#         for informative_ratio in informative_ratios:\n",
    "#             print(f\"Informative ratio: {informative_ratio}\")\n",
    "\n",
    "#             mse_list = []\n",
    "#             precision5_list = []\n",
    "#             precision10_list = []\n",
    "\n",
    "#             for sim in tqdm(range(n_simulations), desc=f\"Func {func_num} - Simulations\"):\n",
    "#                 seed = 42 + sim\n",
    "\n",
    "#                 # === Generate data using specified nonlinear function ===\n",
    "#                 X, y, n_features = generate_nonlinear_data(\n",
    "#                     n_observations,\n",
    "#                     n_informative,\n",
    "#                     informative_ratio,\n",
    "#                     noise_amplitude,\n",
    "#                     seed,\n",
    "#                     func_num\n",
    "#                 )\n",
    "\n",
    "#                 # Split explicitly into 100 train and 100 test\n",
    "#                 X_train, y_train = X[:n_observations_train], y[:n_observations_train]\n",
    "#                 X_test, y_test = X[n_observations_train:], y[n_observations_train:]\n",
    "\n",
    "#                 # === Random Forest model ===\n",
    "#                 rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "#                 # Parameter grid for hyperparameter tuning\n",
    "#                 rf_param_grid = {\n",
    "#                     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#                     'max_depth': [None, 10, 20],\n",
    "#                     'min_samples_split': [2, 5],\n",
    "#                     'min_samples_leaf': [1, 2, 4],\n",
    "#                     'max_features': ['sqrt', 'log2', 1, max(1, n_features // 3)]\n",
    "#                 }\n",
    "\n",
    "#                 # Grid search with cross-validation\n",
    "#                 grid_search = GridSearchCV(\n",
    "#                     rf,\n",
    "#                     param_grid=rf_param_grid,\n",
    "#                     cv=n_folds,\n",
    "#                     scoring='neg_mean_squared_error',\n",
    "#                     n_jobs=-1\n",
    "#                 )\n",
    "\n",
    "#                 # Fit model\n",
    "#                 grid_search.fit(X_train, y_train)\n",
    "#                 best_model = grid_search.best_estimator_\n",
    "\n",
    "#                 # Predict and evaluate\n",
    "#                 y_pred = best_model.predict(X_test)\n",
    "#                 mse = mean_squared_error(y_test, y_pred)\n",
    "#                 mse_list.append(mse)\n",
    "\n",
    "#                 # === Compute precision@5 and precision@10 using feature importances ===\n",
    "#                 importances = best_model.feature_importances_\n",
    "#                 top_5_indices = np.argsort(importances)[-5:][::-1]\n",
    "#                 top_10_indices = np.argsort(importances)[-10:][::-1]\n",
    "\n",
    "#                 correct_top_5 = np.sum(top_5_indices < n_informative)\n",
    "#                 correct_top_10 = np.sum(top_10_indices < n_informative)\n",
    "\n",
    "#                 precision5 = correct_top_5 / 5\n",
    "#                 precision10 = correct_top_10 / 10 # Mistake! Later corrected\n",
    "\n",
    "#                 precision5_list.append(precision5)\n",
    "#                 precision10_list.append(precision10)\n",
    "\n",
    "#             # Aggregate metrics\n",
    "#             mean_mse = np.mean(mse_list)\n",
    "#             std_mse = np.std(mse_list)\n",
    "#             mean_precision5 = np.mean(precision5_list)\n",
    "#             std_precision5 = np.std(precision5_list)\n",
    "#             mean_precision10 = np.mean(precision10_list)\n",
    "#             std_precision10 = np.std(precision10_list)\n",
    "\n",
    "#             rf_nonlinear_functions_results.append({\n",
    "#                 'function_number': func_num,\n",
    "#                 'noise': noise_amplitude,\n",
    "#                 'informative_ratio': informative_ratio,\n",
    "#                 'n_features': n_features,\n",
    "#                 'mean_mse': mean_mse,\n",
    "#                 'std_mse': std_mse,\n",
    "#                 'mean_precision5': mean_precision5,\n",
    "#                 'std_precision5': std_precision5,\n",
    "#                 'mean_precision10': mean_precision10,\n",
    "#                 'std_precision10': std_precision10\n",
    "#             })\n",
    "\n",
    "# # Save results to CSV\n",
    "# df_rf_results = pd.DataFrame(rf_nonlinear_functions_results)\n",
    "# df_rf_results.to_csv('RF_nonlinear_functions_mean_MSE.csv', index=False)\n",
    "# print(\"Saved Random Forest nonlinear functions mean MSE results to 'RF_nonlinear_functions_mean_MSE.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cf581",
   "metadata": {},
   "source": [
    "## 2.5 Results Non-Linear Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef12695",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd1c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load results ===\n",
    "df_ridge = pd.read_csv('Ridge_nonlinear_functions_mean_MSE.csv')\n",
    "df_lasso = pd.read_csv('Lasso_nonlinear_functions_mean_MSE.csv')\n",
    "df_rf = pd.read_csv('RF_nonlinear_functions_mean_MSE.csv')\n",
    "\n",
    "# === Rename columns to avoid collision ===\n",
    "df_ridge = df_ridge.rename(columns={'mean_mse': 'ridge_mse'})\n",
    "df_lasso = df_lasso.rename(columns={'mean_mse': 'lasso_mse'})\n",
    "df_rf = df_rf.rename(columns={'mean_mse': 'rf_mse'})\n",
    "# === Rename columns to avoid collision ===\n",
    "df_rf = df_rf.rename(columns={\n",
    "    'mean_precision5': 'rf_precision5',\n",
    "    'mean_precision10': 'rf_precision10'\n",
    "})\n",
    "df_lasso = df_lasso.rename(columns={\n",
    "    'mean_precision5': 'lasso_precision5',\n",
    "    'mean_precision10': 'lasso_precision10'\n",
    "})\n",
    "df_ridge = df_ridge.rename(columns={\n",
    "    'mean_precision5': 'ridge_precision5',\n",
    "    'mean_precision10': 'ridge_precision10'\n",
    "})\n",
    "\n",
    "\n",
    "# === Merge on common keys ===\n",
    "merge_keys = ['function_number', 'noise', 'informative_ratio', 'n_features']\n",
    "\n",
    "# Merge ridge metrics (MSE + precision)\n",
    "df_merged = df_rf.merge(\n",
    "    df_ridge[merge_keys + ['ridge_mse', 'ridge_precision5', 'ridge_precision10']], \n",
    "    on=merge_keys\n",
    ")\n",
    "\n",
    "# Merge lasso metrics (MSE + precision)\n",
    "df_merged = df_merged.merge(\n",
    "    df_lasso[merge_keys + ['lasso_mse', 'lasso_precision5', 'lasso_precision10']], \n",
    "    on=merge_keys\n",
    ")\n",
    "\n",
    "df_merged[\"rf_precision10_corrected\"] = df_merged[\"rf_precision10\"]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73327d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   function_number  noise  informative_ratio  n_features    rf_mse   std_mse  \\\n",
      "0                1   0.01               0.01         500  4.452820  1.215673   \n",
      "1                2   0.01               0.01         500  0.842715  0.125393   \n",
      "2                3   0.01               0.01         500  0.468622  0.096619   \n",
      "3                4   0.01               0.01         500  4.667571  1.598016   \n",
      "4                5   0.01               0.01         500  4.772339  1.681232   \n",
      "5                6   0.01               0.01         500  1.604780  0.356657   \n",
      "6                7   0.01               0.01         500  1.762679  0.371288   \n",
      "\n",
      "   rf_precision5  std_precision5  rf_precision10  std_precision10  ridge_mse  \\\n",
      "0          0.604        0.172000           0.380         0.093808   5.241822   \n",
      "1          0.224        0.064992           0.128         0.049153   1.108070   \n",
      "2          0.228        0.069397           0.130         0.053852   1.020078   \n",
      "3          0.760        0.132665           0.436         0.062482   6.317491   \n",
      "4          0.508        0.139771           0.294         0.070456   7.165089   \n",
      "5          0.348        0.137463           0.218         0.081707   1.827565   \n",
      "6          0.232        0.140627           0.150         0.083066   1.916041   \n",
      "\n",
      "   ridge_precision5  ridge_precision10  lasso_mse  lasso_precision5  \\\n",
      "0             0.340              0.456   5.076747             0.288   \n",
      "1             0.212              0.228   0.774032             0.212   \n",
      "2             0.208              0.208   0.175697             0.208   \n",
      "3             0.556              0.676   5.496146             0.544   \n",
      "4             0.352              0.396   4.936369             0.424   \n",
      "5             0.232              0.236   1.609382             0.212   \n",
      "6             0.044              0.060   1.913722             0.008   \n",
      "\n",
      "   lasso_precision10  rf_precision10_corrected  \n",
      "0              0.348                     0.760  \n",
      "1              0.224                     0.256  \n",
      "2              0.216                     0.260  \n",
      "3              0.616                     0.872  \n",
      "4              0.472                     0.588  \n",
      "5              0.224                     0.436  \n",
      "6              0.008                     0.300  \n"
     ]
    }
   ],
   "source": [
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e761414",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_merged = df_merged.copy()\n",
    "\n",
    "# Absolute differences\n",
    "test_df_merged[\"difference_Ridge\"] = test_df_merged[\"ridge_mse\"] - test_df_merged[\"rf_mse\"]\n",
    "test_df_merged[\"difference_Lasso\"] = test_df_merged[\"lasso_mse\"] - test_df_merged[\"rf_mse\"]\n",
    "test_df_merged[\"difference_mean\"] = (test_df_merged[\"difference_Ridge\"] + test_df_merged[\"difference_Lasso\"]) / 2\n",
    "\n",
    "# Percentage improvements\n",
    "test_df_merged[\"pct_improvement_Ridge\"] = 100 * (test_df_merged[\"ridge_mse\"] - test_df_merged[\"rf_mse\"]) / test_df_merged[\"ridge_mse\"]\n",
    "test_df_merged[\"pct_improvement_Lasso\"] = 100 * (test_df_merged[\"lasso_mse\"] - test_df_merged[\"rf_mse\"]) / test_df_merged[\"lasso_mse\"]\n",
    "test_df_merged[\"pct_improvement_mean\"] = (test_df_merged[\"pct_improvement_Ridge\"] + test_df_merged[\"pct_improvement_Lasso\"]) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7da06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
